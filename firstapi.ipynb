{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43a7006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "company = input(\"Enter company name or ticker: \").strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "894f385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # -----------------------------\n",
    "# # CONFIG\n",
    "# # -----------------------------\n",
    "# # REPLACE WITH YOUR REAL EMAIL OR SEC WILL BLOCK YOU\n",
    "# HEADERS = {\"User-Agent\": \"YourName yourname@example.com\"}\n",
    "\n",
    "# def find_cik(company_name: str) -> str:\n",
    "#     url = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "#     res = requests.get(url, headers=HEADERS)\n",
    "#     res.raise_for_status()\n",
    "#     data = res.json()\n",
    "\n",
    "#     for item in data.values():\n",
    "#         if company_name.lower() in item[\"title\"].lower() or company_name.lower() in item[\"ticker\"].lower():\n",
    "#             cik = str(item[\"cik_str\"]).zfill(10)\n",
    "#             return cik\n",
    "#     raise ValueError(f\"Company '{company_name}' not found.\")\n",
    "\n",
    "# def get_financials(cik: str):\n",
    "#     url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "#     res = requests.get(url, headers=HEADERS)\n",
    "#     res.raise_for_status()\n",
    "#     data = res.json()\n",
    "\n",
    "#     facts = data.get(\"facts\", {}).get(\"us-gaap\", {})\n",
    "\n",
    "#     def get_latest_fact(tags):\n",
    "#         \"\"\"Checks multiple possible tags and returns the most recent USD value.\"\"\"\n",
    "#         if isinstance(tags, str):\n",
    "#             tags = [tags]\n",
    "            \n",
    "#         for tag in tags:\n",
    "#             if tag in facts:\n",
    "#                 units = facts[tag].get(\"units\", {}).get(\"USD\", [])\n",
    "#                 if units:\n",
    "#                     # Sort by 'end' date to ensure we get the most recent period\n",
    "#                     latest = sorted(units, key=lambda x: x.get('end', ''))[-1]\n",
    "#                     return {\n",
    "#                         \"val\": latest[\"val\"],\n",
    "#                         \"end\": latest[\"end\"],\n",
    "#                         \"form\": latest.get(\"form\", \"N/A\")\n",
    "#                     }\n",
    "#         return None\n",
    "\n",
    "#     # Capex is usually found in the Statement of Cash Flows\n",
    "#     capex_data = get_latest_fact([\n",
    "#         \"PaymentsToAcquirePropertyPlantAndEquipment\", \n",
    "#         \"PaymentsToAcquireProductiveAssets\"\n",
    "#     ])\n",
    "\n",
    "#     results = {\n",
    "#         \"Revenue\": get_latest_fact(\"Revenues\"),\n",
    "#         \"Net Income\": get_latest_fact(\"NetIncomeLoss\"),\n",
    "#         \"Total Assets\": get_latest_fact(\"Assets\"),\n",
    "#         \"Capex\": capex_data\n",
    "#     }\n",
    "#     return results\n",
    "\n",
    "# # -----------------------------\n",
    "# # Execution\n",
    "# # -----------------------------\n",
    "# try:\n",
    "#     cik = find_cik(company)\n",
    "#     data = get_financials(cik)\n",
    "\n",
    "#     print(f\"\\n--- Financial Data for CIK: {cik} ---\")\n",
    "#     for metric, info in data.items():\n",
    "#         if info:\n",
    "#             # Formatting large numbers for readability\n",
    "#             readable_val = f\"${info['val']:,.2f}\"\n",
    "#             print(f\"{metric:15} | {readable_val:>20} | Period: {info['end']} ({info['form']})\")\n",
    "#         else:\n",
    "#             print(f\"{metric:15} | Data Not Found\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "421d1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f2ec2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_financials(cik: str,metric_name:str):\n",
    "#     url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "#     res = requests.get(url, headers=HEADERS)\n",
    "#     res.raise_for_status()\n",
    "#     data = res.json()\n",
    "#     if 'facts' in data:\n",
    "#         # Standard structure: data['facts']['us-gaap'][metric_name]\n",
    "#         metric_data = None\n",
    "#         for taxonomy in data['facts'].values():\n",
    "#             if metric_name in taxonomy:\n",
    "#                 metric_data = taxonomy[metric_name]\n",
    "#                 break\n",
    "#     else:\n",
    "#         # Snippet structure\n",
    "#         metric_data = data.get(metric_name)\n",
    "\n",
    "#     if not metric_data:\n",
    "#         print(f\"Error: Metric '{metric_name}' not found.\")\n",
    "#         return\n",
    "\n",
    "#     # 3. Extract USD time-series data\n",
    "#     usd_list = metric_data.get('units', {}).get('USD', [])\n",
    "#     if not usd_list:\n",
    "#         print(f\"Error: No USD data for {metric_name}.\")\n",
    "#         return\n",
    "\n",
    "#     # 4. Create DataFrame and convert dates\n",
    "#     df = pd.DataFrame(usd_list)\n",
    "#     df['end'] = pd.to_datetime(df['end'])\n",
    "#     df['filed'] = pd.to_datetime(df['filed'])\n",
    "\n",
    "#     # 5. DEDUPLICATION LOGIC\n",
    "#     # SEC data repeats values across filings. We prioritize 10-K over 10-Q \n",
    "#     # and always keep the most recently filed version for any given date.\n",
    "#     form_priority = {'10-K': 1, '10-Q': 2, '8-K': 3}\n",
    "#     df['priority'] = df['form'].map(lambda x: form_priority.get(x, 4))\n",
    "    \n",
    "#     # Sort by date, then form priority, then the date it was filed\n",
    "#     df = df.sort_values(by=['end', 'priority', 'filed'], ascending=[True, True, False])\n",
    "    \n",
    "#     # Keep only one unique data point per period end date\n",
    "#     df_clean = df.drop_duplicates(subset=['end'], keep='first')\n",
    "\n",
    "#     # 6. Visualization\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "    \n",
    "#     # Divide by 1 Billion for a cleaner Y-axis\n",
    "#     plt.plot(df_clean['end'], df_clean['val'] / 1e9, marker='s', color='#2c3e50', linewidth=2)\n",
    "    \n",
    "#     plt.title(metric_data.get('label', metric_name), fontsize=12, fontweight='bold')\n",
    "#     plt.xlabel(\"Period End Date\")\n",
    "#     plt.ylabel(\"Billions (USD)\")\n",
    "#     plt.grid(True, linestyle=':', alpha=0.7)\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     # plt.savefig('sec_metric_plot.png')\n",
    "#     # print(f\"Plot generated for {metric_name} and saved as sec_metric_plot.png\")\n",
    "\n",
    "# # --- Usage ---\n",
    "# # Ensure your data is saved in 'company_facts.json'\n",
    "# # You can use any metric like 'NetIncomeLoss' or the one provided below\n",
    "\n",
    "# get_financials(cik,\"PaymentsToAcquirePropertyPlantAndEquipment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48de943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_capex_breakdown(cik: str):\n",
    "#     url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "#     res = requests.get(url, headers=HEADERS)\n",
    "#     res.raise_for_status()\n",
    "#     facts = res.json().get(\"facts\", {}).get(\"us-gaap\", {})\n",
    "\n",
    "#     search_map = {\n",
    "#         \"Total Capex\": [\"PaymentsToAcquirePropertyPlantAndEquipment\", \"PaymentsToAcquireProductiveAssets\"],\n",
    "#         \"Software/Intangibles\": [\"PaymentsToAcquireSoftware\", \"CapitalizedComputerSoftwareCosts\"],\n",
    "#         \"Land\": [\"PaymentsToAcquireLand\"]\n",
    "#     }\n",
    "\n",
    "#     breakdown = {}\n",
    "#     for label, tags in search_map.items():\n",
    "#         for tag in tags:\n",
    "#             if tag in facts:\n",
    "#                 # Logic to get 'latest' as you had it\n",
    "#                 units = facts[tag].get(\"units\", {}).get(\"USD\", [])\n",
    "#                 if units:\n",
    "#                     latest = sorted(units, key=lambda x: x.get('end', ''))[-1]\n",
    "#                     breakdown[label] = {\"val\": latest[\"val\"], \"period\": latest[\"end\"]}\n",
    "#                     break # Stop looking for this label once a tag is found\n",
    "    \n",
    "#     return breakdown\n",
    "\n",
    "# # Usage\n",
    "# breakdown = get_capex_breakdown(cik) # Apple Example\n",
    "# breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2354c9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CIK for ASML HOLDING NV: 0000937966\n",
      "Error: No ('10-K', '10-Q') filing found for CIK 0000937966.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "HEADERS = {\"User-Agent\": \"yourname your@email.com\"}\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Find CIK from company name\n",
    "# -----------------------------\n",
    "def find_cik(company_name: str) -> str:\n",
    "    url = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "    res = requests.get(url, headers=HEADERS)\n",
    "    res.raise_for_status()\n",
    "    data = res.json()\n",
    "\n",
    "    for item in data.values():\n",
    "        if company_name.lower() in item[\"title\"].lower():\n",
    "            cik = str(item[\"cik_str\"]).zfill(10)\n",
    "            print(f\"Found CIK for {item['title']}: {cik}\")\n",
    "            return cik\n",
    "    raise ValueError(f\"Company '{company_name}' not found in SEC tickers.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Get latest filings\n",
    "# -----------------------------\n",
    "def get_latest_filing(cik: str, form_types=(\"10-K\",\"10-Q\")) -> dict:\n",
    "    url = f\"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
    "    res = requests.get(url, headers=HEADERS)\n",
    "    res.raise_for_status()\n",
    "    data = res.json()\n",
    "\n",
    "    for filing in data[\"filings\"][\"recent\"][\"form\"]:\n",
    "        if filing in form_types:\n",
    "            idx = data[\"filings\"][\"recent\"][\"form\"].index(filing)\n",
    "            accession_number = data[\"filings\"][\"recent\"][\"accessionNumber\"][idx].replace(\"-\", \"\")\n",
    "            primary_doc = data[\"filings\"][\"recent\"][\"primaryDocument\"][idx]\n",
    "            filing_url = f\"https://www.sec.gov/Archives/edgar/data/{int(cik)}/{accession_number}/{primary_doc}\"\n",
    "            return {\n",
    "                \"form\": filing,\n",
    "                \"date\": data[\"filings\"][\"recent\"][\"filingDate\"][idx],\n",
    "                \"url\": filing_url\n",
    "            }\n",
    "    raise ValueError(f\"No {form_types} filing found for CIK {cik}.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Get structured financials (companyfacts API)\n",
    "# -----------------------------\n",
    "def get_financials(cik: str):\n",
    "    url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    res = requests.get(url, headers=HEADERS)\n",
    "    res.raise_for_status()\n",
    "    data = res.json()\n",
    "\n",
    "    facts = data.get(\"facts\", {}).get(\"us-gaap\", {})\n",
    "\n",
    "    def get_latest(tag):\n",
    "        if tag in facts:\n",
    "            units = facts[tag][\"units\"]\n",
    "            if \"USD\" in units and len(units[\"USD\"]) > 0:\n",
    "                return units[\"USD\"][-1][\"val\"]\n",
    "        return None\n",
    "\n",
    "    financials = {\n",
    "        \"Revenue\": get_latest(\"Revenues\"),\n",
    "        \"Net Income\": get_latest(\"NetIncomeLoss\"),\n",
    "        \"Total Assets\": get_latest(\"Assets\"),\n",
    "        \"Total Liabilities\": get_latest(\"Liabilities\"),\n",
    "        \"Equity\": get_latest(\"StockholdersEquity\")\n",
    "    }\n",
    "    return financials\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "# company = input(\"Enter company name: \").strip()\n",
    "try:\n",
    "    cik = find_cik(company)\n",
    "    latest_filing = get_latest_filing(cik)\n",
    "    financials = get_financials(cik)\n",
    "\n",
    "    print(\"\\n=== Latest Filing ===\")\n",
    "    print(f\"Form: {latest_filing['form']}\")\n",
    "    print(f\"Date: {latest_filing['date']}\")\n",
    "    print(f\"Filing URL: {latest_filing['url']}\")\n",
    "\n",
    "    print(\"\\n=== Key Financials (Latest) ===\")\n",
    "    for k, v in financials.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f414d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrant: VWF Bancorp, Inc.\n",
      "CIK: 0001913838\n",
      "\n",
      "=== CAPEX Data ===\n",
      "us-gaap:PaymentsToAcquirePropertyPlantAndEquipment: [964987.0, 673197.0]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "HEADERS = {\n",
    "    'User-Agent': 'FinancialDataExtractor/1.0 (contact@example.com)'\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Function to parse XBRL filing\n",
    "# -----------------------------\n",
    "def transform_report_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": f\"Failed to retrieve URL: {e}\"}\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    results = {}\n",
    "\n",
    "    # 1. Extract non-numeric identifiers (Company Name, CIK, etc.)\n",
    "    for tag in soup.find_all('ix:nonnumeric'):\n",
    "        name = tag.get('name')\n",
    "        if name:\n",
    "            value = \" \".join(tag.get_text().split())\n",
    "            results[name] = value\n",
    "\n",
    "    # 2. Extract numeric financial values\n",
    "    for tag in soup.find_all('ix:nonfraction'):\n",
    "        name = tag.get('name')\n",
    "        if not name:\n",
    "            continue\n",
    "\n",
    "        raw_text = tag.get_text().strip().replace(',', '')\n",
    "        if not raw_text or raw_text == '—' or tag.get('xsi:nil') == 'true':\n",
    "            value = 0.0\n",
    "        else:\n",
    "            try:\n",
    "                value = float(raw_text)\n",
    "                scale = tag.get('scale')\n",
    "                if scale:\n",
    "                    value *= (10 ** int(scale))\n",
    "                if tag.get('sign') == '-':\n",
    "                    value = -abs(value)\n",
    "            except ValueError:\n",
    "                value = raw_text\n",
    "\n",
    "        if name in results:\n",
    "            if not isinstance(results[name], list):\n",
    "                results[name] = [results[name]]\n",
    "            results[name].append(value)\n",
    "        else:\n",
    "            results[name] = value\n",
    "\n",
    "    # 3. Extract CAPEX-related data\n",
    "    capex_tags = [\n",
    "        \"us-gaap:PropertyPlantAndEquipmentAdditions\",\n",
    "        \"us-gaap:CapitalExpenditures\",\n",
    "        \"us-gaap:PaymentsToAcquirePropertyPlantAndEquipment\",\n",
    "    ]\n",
    "\n",
    "    capex_data = {}\n",
    "    for tag_name in capex_tags:\n",
    "        if tag_name in results:\n",
    "            capex_data[tag_name] = results[tag_name]\n",
    "\n",
    "    results['CAPEX'] = capex_data\n",
    "    return results\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "latest_filing_url = latest_filing['url']\n",
    "\n",
    "financial_data = transform_report_from_url(latest_filing_url)\n",
    "\n",
    "if \"error\" in financial_data:\n",
    "    print(financial_data[\"error\"])\n",
    "else:\n",
    "    # Non-numeric identifiers\n",
    "    print(f\"Registrant: {financial_data.get('dei:EntityRegistrantName')}\")\n",
    "    print(f\"CIK: {financial_data.get('dei:EntityCentralIndexKey')}\\n\")\n",
    "\n",
    "    # Some key financials\n",
    "\n",
    "    # CAPEX\n",
    "    print(\"=== CAPEX Data ===\")\n",
    "    for k, v in financial_data.get('CAPEX', {}).items():\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90e34158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from ddgs import DDGS\n",
    "import anthropic\n",
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "QUERIES = [\n",
    "    \"{company} management report 2025 filetype:pdf\",\n",
    "    \"{company} annual management report 2025 filetype:pdf\",\n",
    "    \"{company} management discussion and analysis 2025 filetype:pdf\",\n",
    "    \"{company} MD&A report 2025 filetype:pdf\",\n",
    "    \"{company} directors report 2025 filetype:pdf\",\n",
    "    \"{company} board report 2025 filetype:pdf\",\n",
    "    \"{company} annual report 2025 management section filetype:pdf\",\n",
    "    \"{company} executive management report 2025 pdf\",\n",
    "    \"{company} leadership report 2025 filetype:pdf\",\n",
    "    \"{company} operational report 2025 filetype:pdf\",\n",
    "    \"{company} financial review 2025 management report pdf\",\n",
    "    \"{company} strategic report 2025 filetype:pdf\",\n",
    "    \"{company} corporate report 2025 management pdf\",\n",
    "    \"{company} management report site:{company_slug}.com\",\n",
    "    \"{company} business review 2025 filetype:pdf\",\n",
    "    \"{company} company performance report 2025 pdf\",\n",
    "    \"{company} annual performance report 2025 filetype:pdf\",\n",
    "    \"{company} consolidated management report 2025 pdf\",\n",
    "    \"{company} governance and management report 2025 filetype:pdf\",\n",
    "    \"{company} management summary report 2025 pdf\",\n",
    "]\n",
    "\n",
    "\n",
    "def iter_esg_results(company: str):\n",
    "    \"\"\"Generator: yields search results one query at a time, stopping when called to.\"\"\"\n",
    "    seen_urls = set()\n",
    "    slug = company.lower().replace(\" \", \"\")\n",
    "\n",
    "    for i, template in enumerate(QUERIES):\n",
    "        query = template.format(company=company, company_slug=slug)\n",
    "        print(f\"[{i+1}/{len(QUERIES)}] Searching: {query}\")\n",
    "        try:\n",
    "            with DDGS() as ddgs:\n",
    "                results = list(ddgs.text(query, max_results=5))\n",
    "            for r in results:\n",
    "                url = r.get(\"href\", \"\")\n",
    "                if url and url not in seen_urls:\n",
    "                    seen_urls.add(url)\n",
    "                    yield r\n",
    "        except Exception as e:\n",
    "            print(f\"  Search failed: {e}\")\n",
    "\n",
    "\n",
    "def try_download_pdf(company: str, url: str) -> str | None:\n",
    "    \"\"\"Try to download a single URL as a PDF. Returns file path on success, None otherwise.\"\"\"\n",
    "    if not url.lower().endswith(\".pdf\"):\n",
    "        return None\n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        content_type = response.headers.get(\"Content-Type\", \"\").lower()\n",
    "        if response.status_code == 200 and \"pdf\" in content_type:\n",
    "            os.makedirs(\"reports\", exist_ok=True)\n",
    "            filename = f\"reports/{company.replace(' ', '_')}_ESG_report.pdf\"\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded: {filename}\\nSource: {url}\")\n",
    "            return filename\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to download {url}: {e}\")\n",
    "    return None\n",
    "\n",
    "@lru_cache(maxsize=10)\n",
    "def find_and_download_esg_pdf(company: str) -> str | None:\n",
    "    \"\"\"Iterate search results and stop as soon as a PDF is successfully downloaded.\"\"\"\n",
    "    for result in iter_esg_results(company):\n",
    "        url = result.get(\"href\", \"\")\n",
    "        pdf_path = try_download_pdf(company, url)\n",
    "        if pdf_path:\n",
    "            print(\"PDF found — stopping search early.\")\n",
    "            return pdf_path\n",
    "\n",
    "    print(\"Search exhausted. No PDF could be downloaded.\")\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87e967b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/20] Searching: asml management report 2025 filetype:pdf\n",
      "Downloaded: reports/asml_ESG_report.pdf\n",
      "Source: https://ourbrand.asml.com/m/39670b708ea03976/original/2025_07_16_Presentation-Investor-Relations-Q2-2025.pdf\n",
      "PDF found — stopping search early.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'reports/asml_ESG_report.pdf'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_and_download_esg_pdf(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "323086a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import anthropic\n",
    "# import base64\n",
    "# import fitz  # pymupdf\n",
    "# import os\n",
    "\n",
    "\n",
    "# def analyze_esg_chunk(client: anthropic.Anthropic, company: str, text: str, page_start: int, page_end: int) -> str:\n",
    "#     \"\"\"Send extracted text chunk to Claude for ESG analysis.\"\"\"\n",
    "#     response = client.messages.create(\n",
    "#         model=\"claude-opus-4-6\",\n",
    "#         max_tokens=4096,\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": f\"\"\"Analyze this section of {company}'s ESG report (pages {page_start}-{page_end}) and split all content into two clear categories:\n",
    "\n",
    "# ## 1. QUANTIFIABLE DATA\n",
    "# Extract every concrete, measurable figure mentioned. For each one include:\n",
    "# - Metric name\n",
    "# - Value + unit\n",
    "# - Year / time period\n",
    "# - Context (what it refers to)\n",
    "\n",
    "# Examples of what to look for:\n",
    "# - Financial investments (e.g. datacenter spend, renewable energy investment)\n",
    "# - Emissions (CO2, Scope 1/2/3 in tonnes)\n",
    "# - Energy consumption (MWh, GWh)\n",
    "# - Water usage (litres, m³)\n",
    "# - Waste (tonnes recycled/landfilled)\n",
    "# - Workforce stats (headcount, % women in leadership, pay gap %)\n",
    "# - Certifications, targets with deadlines and % progress\n",
    "# - Supply chain figures (# suppliers audited, % compliant)\n",
    "\n",
    "# ## 2. CORPORATE SPEAK\n",
    "# Flag all vague, unverifiable, or purely qualitative claims. For each one include:\n",
    "# - The exact phrase or sentence\n",
    "# - Why it's vague (no metric, no deadline, no baseline, etc.)\n",
    "# - Suspected intent (reputation management, regulatory compliance, etc.)\n",
    "\n",
    "# Be thorough and critical. Format your response clearly under these two headings.\n",
    "\n",
    "# --- REPORT TEXT ---\n",
    "# {text}\"\"\"\n",
    "#             }\n",
    "#         ],\n",
    "#     )\n",
    "#     return response.content[0].text\n",
    "\n",
    "\n",
    "# def analyze_esg_pdf(company: str, pdf_path: str) -> str:\n",
    "#     \"\"\"Extract text from PDF, chunk it, and analyze each chunk.\"\"\"\n",
    "#     print(f\"\\nOpening PDF: {pdf_path}\")\n",
    "\n",
    "#     client = anthropic.Anthropic()\n",
    "#     doc = fitz.open(pdf_path)\n",
    "#     total_pages = len(doc)\n",
    "#     chunk_size = 50\n",
    "#     results = []\n",
    "\n",
    "#     print(f\"Total pages: {total_pages}\")\n",
    "\n",
    "#     for start in range(0, total_pages, chunk_size):\n",
    "#         end = min(start + chunk_size, total_pages)\n",
    "#         print(f\"\\nAnalyzing pages {start+1} to {end}...\")\n",
    "\n",
    "#         # Extract text from pages\n",
    "#         text = \"\"\n",
    "#         for page_num in range(start, end):\n",
    "#             text += f\"\\n--- Page {page_num+1} ---\\n\"\n",
    "#             text += doc[page_num].get_text()\n",
    "\n",
    "#         if not text.strip():\n",
    "#             print(f\"No text found on pages {start+1}-{end}, skipping...\")\n",
    "#             continue\n",
    "\n",
    "#         result = analyze_esg_chunk(client, company, text, start + 1, end)\n",
    "#         results.append(f\"## Pages {start+1}-{end}\\n\\n{result}\")\n",
    "\n",
    "#     doc.close()\n",
    "\n",
    "#     final_report = f\"# ESG Analysis: {company}\\n\\n\" + \"\\n\\n---\\n\\n\".join(results)\n",
    "#     return final_report\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     company = \"YourCompany\"\n",
    "# #     pdf_path = \"report.pdf\"\n",
    "\n",
    "# #     report = analyze_esg_pdf(company, pdf_path)\n",
    "    \n",
    "# #     # Save to file\n",
    "# #     output_path = f\"{company}_esg_analysis.txt\"\n",
    "# #     with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "# #         f.write(report)\n",
    "    \n",
    "# #     print(f\"\\nAnalysis saved to {output_path}\")\n",
    "# def save_analysis(company: str, analysis: str) -> str:\n",
    "#     \"\"\"Save Claude's analysis to a text file. Returns the file path.\"\"\"\n",
    "#     analysis_path = f\"reports/{company.replace(' ', '_')}_ESG_analysis.txt\"\n",
    "#     with open(analysis_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(f\"ESG REPORT ANALYSIS: {company}\\n\")\n",
    "#         f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "#         f.write(analysis)\n",
    "#     print(f\"Analysis saved to: {analysis_path}\")\n",
    "#     return analysis_path\n",
    "\n",
    "\n",
    "# def get_latest_esg_report(company: str) -> dict:\n",
    "#     \"\"\"Orchestrator: search (with early termination), download, analyze, and save.\"\"\"\n",
    "#     pdf_path = find_and_download_esg_pdf(company)\n",
    "#     if not pdf_path:\n",
    "#         return {\"company\": company, \"downloaded\": None, \"analysis\": None, \"analysis_path\": None}\n",
    "\n",
    "#     analysis = analyze_esg_pdf(company, pdf_path)\n",
    "#     analysis_path = save_analysis(company, analysis)\n",
    "\n",
    "#     return {\n",
    "#         \"company\": company,\n",
    "#         \"downloaded\": pdf_path,\n",
    "#         \"analysis_path\": analysis_path,\n",
    "#         \"analysis\": analysis,\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02826a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Run ---\n",
    "# result = get_latest_esg_report(company)\n",
    "# print(f\"\\n{'='*60}\")\n",
    "# print(f\"ANALYSIS FOR: {company}\")\n",
    "# print(f\"{'='*60}\")\n",
    "# print(result[\"analysis\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
